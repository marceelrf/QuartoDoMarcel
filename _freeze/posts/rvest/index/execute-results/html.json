{
  "hash": "397a6e6a3bdc36f6d1be26bfbc388e87",
  "result": {
    "markdown": "---\ntitle: \"Using Rvest and Tidyverse to scrape the samples names from 1000 genomes\"\ndescription: \"\"\nauthor: \"Marcel Ferreira\"\ndate: \"2023-06-22\"\ncategories: [R, Bioinformatics, Webscrapping]\nimage: \"1000genomes.jpg\"\ninclude-in-header: \"../../asScript.js\"\nbibliography: references.bib\n---\n\n\nCurrently in my postdoc project I am downloading sequencing files using Oxford Nanopore Technologies (**ONT**) from the 1000 genomes database (https://www.internationalgenome.org/). But after I started the downloads I noticed that the name of the downloaded file **did not** contain any sample code.\n\n![Files from 1000 genomes](Imagem1.png)\n\nSo at first I despaired and figured that I would have to manually collect information from almost 40 samples (in this step) and several more in future steps. A process highly susceptible to human error (not to mention laziness, right?).\n\nTaking all this into account I thought \"why not use R and try to scrape this information straight from the website?\". And the result was pretty cool! I hope it helps you in similar projects!\n\n![Files webpage structure](Imagem2.png)\n\n## Libraries\n\nIn this work I used the `{rvest}`[@rvest] library to scrape the data and, of course, `{tidyverse}` [@tidyverse] to handle the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.0     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.1     v tibble    3.1.8\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.1     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(rvest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'rvest'\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n```\n:::\n:::\n\n\n## The FTP site for data download\n\nThe site for downloading the data in my project was as follows:\n\nhttp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/HGSVC3/working/20211013_ONT_Rebasecalled/\n\nI used the functions `read_html()` and `html_node()`, with the argument `\"table\"`,to extract as a table the sample structure information on the site.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmil_genomes <- \"http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/HGSVC3/working/20211013_ONT_Rebasecalled/\"\n\nwebpage <- read_html(mil_genomes)\n\ntbls <- html_nodes(webpage, \"table\")\n```\n:::\n\n\nThe `tbls` object is a R `list`, then it is necessary to extract the first element of the list to follow the analysis. The function `html_table()` return a `tibble` object containing the sample table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbls[[1]] %>% \n  html_table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 47 x 5\n   ``    Name               `Last modified`    Size  Description\n   <lgl> <chr>              <chr>              <chr> <lgl>      \n 1 NA    \"\"                 \"\"                 \"\"    NA         \n 2 NA    \"Parent Directory\" \"\"                 \"-\"   NA         \n 3 NA    \"HG00096/\"         \"2023-07-24 15:42\" \"-\"   NA         \n 4 NA    \"HG00268/\"         \"2022-05-31 09:55\" \"-\"   NA         \n 5 NA    \"HG00358/\"         \"2022-11-07 10:42\" \"-\"   NA         \n 6 NA    \"HG00512/\"         \"2022-06-01 14:56\" \"-\"   NA         \n 7 NA    \"HG00731/\"         \"2022-06-01 15:16\" \"-\"   NA         \n 8 NA    \"HG00733/\"         \"2022-11-07 10:36\" \"-\"   NA         \n 9 NA    \"HG01457/\"         \"2022-05-31 09:54\" \"-\"   NA         \n10 NA    \"HG01505/\"         \"2022-06-01 15:24\" \"-\"   NA         \n# ... with 37 more rows\n```\n:::\n:::\n\n\nThe table contains unwanted columns and rows, so I used the following strategy to clean up this data:\n\nThe `select()` function from the `{dplyr}` [@dplyr] package was used to remove the first column, which had only empty cells. The `filter()` function from `{dplyr}` combined with the `str_detect()` from `{stringr}` [@stringr] package was used to filter the lines with the sample names using the pattern \"NA\" or \"HG\". Finally, I used the `Name` column to create `Name_sample` columns, containing the sample code, and `Name_dir`, which contained the sample directory path (thinking about the next step). The final object was save to the `samples_names`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples_names <- tbls[[1]] %>% \n  html_table() %>% \n  select(-1) %>% \n  filter(str_detect(Name,pattern = \"NA|HG\")) %>% \n  mutate(Name_sample = Name,\n         Name_dir = Name) %>% \n  mutate(Name_sample = str_replace(Name_sample,\"\\\\/\",\"\")) %>% \n  select(Name_sample,Name_dir)\n```\n:::\n\n\nWith this step complete, I set about extracting the names of the different files in each sample folder. I used the famous `group_by()` \\> `nest()` \\> `mutate()` \\> `map()` pipeline to speed up the process. Applying the `group_by()`, from `dplyr`, in the `Name_sample` column and then the `nest()`, from `{tidyr}` [@tidyr], we produce a nested tibble, that means, a table with a list-column! And the `map()` function, from the `{purrr}` [@purrr], its used to apply functions to all elements in a list. So, this can easily be used inside a `mutate()`, from `{dplyr}`, and create a new list-column, with the final results. And at the end, we use `unnest()`, from `{tidyr}`, to transform the list-column to the traditional table format.\n\nSo to accomplish this I just needed to write a custom function to be applied on each element and extract the sample files. Again, I used the functions `read_html()`, `html_nodes()` and `html_table()` to extract the tables with the filenames. The `glue()` function, from `{glue}` [@glue] package, was used to create the access links automatically.The I clean the table with a similar strategy then before, but now I use the pattern \"guppy\" to filter the rows of interest. I named this function `fn_get_filnames()` and apply in the pipeline.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfn_get_filnames <- function(x) {\n  read_html(glue::glue(\"{mil_genomes}{x$Name_dir}\")) %>% \n    html_nodes(\"table\") %>% \n    .[[1]] %>% \n    html_table() %>%\n    select(-1) %>%\n    filter(str_detect(Name,\"guppy\")) %>% \n    select(Filename = Name,\n           Size)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples_names <- samples_names %>% \n  group_by(Name_sample) %>% \n  nest() %>% \n  mutate(filenames = map(data, fn_get_filnames)) %>% \n  unnest(data,filenames)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `unnest()` has a new interface. See `?unnest` for details.\ni Try `df %>% unnest(c(data, filenames))`, with `mutate()` if needed.\n```\n:::\n:::\n\n\nAnd in the end we had our table!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples_names\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 108 x 4\n# Groups:   Name_sample [36]\n   Name_sample Name_dir Filename                                           Size \n   <chr>       <chr>    <chr>                                              <chr>\n 1 HG00096     HG00096/ 20220405_220329_21-lee-006_PC24B149_3D_guppy-5.0.~ 30G  \n 2 HG00096     HG00096/ 20220408_220405_21-lee-006_PC24B149_2D_guppy-5.0.~ 25G  \n 3 HG00096     HG00096/ 20220412_220407_21-lee-006_PC24B149_2D_guppy-5.0.~ 3.6G \n 4 HG00096     HG00096/ 20230418_230412_23-lee-007_PC24B149_2C_guppy-5.0.~ 63G  \n 5 HG00268     HG00268/ 20210903_210825_21-lee-006_PCT0053_2-A1-D1_guppy-~ 69G  \n 6 HG00268     HG00268/ 20210913_210831_21-lee-006_PCT0053_2-A1-D1_guppy-~ 55G  \n 7 HG00358     HG00358/ 20220211_220202_21-lee-006_PC24B149_1F_guppy-5.0.~ 54G  \n 8 HG00358     HG00358/ 20220215_220209_21-lee-006_PC24B149_2E_guppy-5.0.~ 26G  \n 9 HG00358     HG00358/ 20220315_220308_21-lee-006_PC24B149_3D_guppy-5.0.~ 55G  \n10 HG00512     HG00512/ 20220425_220420_21-lee-006_PC24B149_3F_guppy-5.0.~ 55G  \n# ... with 98 more rows\n```\n:::\n:::\n\n\nI hope this pipeline will help you!\n\nHope to see you in the next ones!\n\nMarcel\n\n#### References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}